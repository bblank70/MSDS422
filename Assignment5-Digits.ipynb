{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Assignment 5 - Digit multiclass classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Requirements\n",
    "    (1) Begin by fitting a random forest classifier using the full set of 784 explanatory variables and the model training set (train.csv). Record the time it takes to fit the model and then evaluate \n",
    "    the model on the test.csv data by submitting to Kaggle.com. Provide your Kaggle.com score and user ID.\n",
    "    \n",
    "    (2) Execute principal components analysis (PCA) on the combined training and test set data together, generating principal components that represent 95 percent of the variability in the explanator \n",
    "    variables. The number of principal components in the solution should be substantially fewer than the 784 explanatory variables. Record the time it takes to identify the principal components.\n",
    "    \n",
    "    (3) Using the identified principal components from step (2), use the train.csv to build another random forest classifier. Record the time it takes to fit the model and to evaluate the model on \n",
    "    the test.csv data by submitting to Kaggle.com. Provide your Kaggle.com score and user ID.\n",
    "\n",
    "    (4) Submit both the RF Classifier and the PCA RF Classifier to Kaggle.com, and report both scores along with your user name.  I MUST have your user name to verify submission status.\n",
    "\n",
    "    (5) The experiment we have proposed has a MAJOR design flaw. Identify the flaw. Fix it. Rerun the experiment in a way that is consistent with a training-and-test regimen, and submit this to \n",
    "    Kaggle.com. Provide your Kaggle.com score and user ID.\n",
    "\n",
    "    (6)  Use k-means clustering to group MNIST observations into 1 of 10 categories and then assign labels. \n",
    "\n",
    "#### Report total elapsed time measures for the training set analysis.  It is sufficient to run a single time-elapsed test for this assignment. In practice, we might consider the possibility of repeated executions of the relevant portions of the programs, much as the Benchmark Example programs do. Some code that might help you with reporting elapsed total time follows. \n",
    "\n",
    "    start=datetime.now()\n",
    "    rf2.fit(trainimages,labels)\n",
    "    end=datetime.now()\n",
    "    print(end-start)  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import base packages into the namespace for this program\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "#diplay and plotting\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "\n",
    "#import from SKlearn\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from  sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    " \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "# read data for the Boston Housing Study\n",
    "Digit_input = pd.read_csv(\"C:/Users/bblank/Documents/Northwestern MSDS/datasets/Digits-Train.csv\")\n",
    "Digit_test = pd.read_csv(\"C:/Users/bblank/Documents/Northwestern MSDS/datasets/test.csv\")\n",
    "#sets random seed for entire notebook\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "#kfold for CV of models\n",
    "kfold = KFold(n_splits=5, random_state=RANDOM_SEED)\n",
    "testkfold = KFold(n_splits=2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5    3795\n",
       "8    4063\n",
       "4    4072\n",
       "0    4132\n",
       "6    4137\n",
       "2    4177\n",
       "9    4188\n",
       "3    4351\n",
       "7    4401\n",
       "1    4684\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#get counts of the labels, check for balance\n",
    "Digit_input.label.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits training data into X and y\n",
    "X_train = Digit_input.label.copy()\n",
    "y_train = Digit_input.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
       "       'pixel7', 'pixel8', 'pixel9',\n",
       "       ...\n",
       "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
       "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
       "      dtype='object', length=784)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": []
  }
 ]
}